# ğŸ“Œ Sentiment Analysis Project

**Logistic Regression + TF-IDF + Manual Preprocessing**

---

## ğŸ“– Overview

This project performs **sentiment analysis** on tweets using:

* manual text preprocessing
* TF-IDF feature extraction
* Logistic Regression classification

The model predicts whether a tweet is:

```
positive
negative
neutral
```

The entire pipeline follows a step-by-step assignment requirement (tokenization â†’ TF-IDF â†’ feature matrix â†’ model â†’ predictions â†’ evaluation).

---

## ğŸ“ Project Structure

```
Sentiment-analysis/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ train.csv              # training dataset
â”‚
â”œâ”€â”€ stop-words-list.txt        # stopwords for preprocessing
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py          # clean and tokenize tweets
â”‚   â”œâ”€â”€ build_features.py      # generate TF-IDF features + labels
â”‚   â”œâ”€â”€ train_model.py         # train Logistic Regression
â”‚   â””â”€â”€ predict_test.py        # predict & evaluate
â”‚
â””â”€â”€ .venv/                     # virtual environment
```

---

## ğŸ§  How It Works (Simple Steps)

### **1. Preprocessing**

`preprocess.py`:

* Converts text to lowercase
* Removes punctuation and symbols
* Tokenizes text into words
* Removes stopwords in `stop-words-list.txt`

### **2. Feature Extraction**

`build_features.py`:

* Loads dataset
* Cleans all tweets
* Converts tweets into numerical features using **TF-IDF**
* Builds vocab up to 10,000 most important words
* Saves:

  * `X_train_sparse.npz` (features)
  * `y_train.csv` (labels)
  * `vectorizer.pkl` (vocab builder)

### **3. Training**

`train_model.py`:

* Loads features and labels
* Trains **Logistic Regression**
* Saves trained model as `model.pkl`

### **4. Prediction & Evaluation**

`predict_test.py`:

* Loads model, vectorizer, and original tweets
* Cleans tweets again (same rules)
* Converts cleaned tweets into feature vectors
* Predicts sentiment
* Prints first 10 tweet + prediction pairs
* Calculates overall accuracy

---

## ğŸ› ï¸ Installation & Setup

### 1ï¸âƒ£ Create and activate a virtual environment

```bash
python -m venv .venv
source .venv/Scripts/activate
```

### 2ï¸âƒ£ Install required packages

```
pandas
numpy
scikit-learn
scipy
```

Run:

```bash
pip install pandas numpy scikit-learn scipy
```

(or create a requirements.txt if needed)

---

## â–¶ï¸ Running the Pipeline

### Step 1 â€” Build Features

```bash
python src/build_features.py
```

Creates:

* `X_train_sparse.npz`
* `y_train.csv`
* `vectorizer.pkl`

### Step 2 â€” Train Model

```bash
python src/train_model.py
```

Creates:

* `model.pkl`

### Step 3 â€” Predict and Evaluate

```bash
python src/predict_test.py
```

Prints examples like:

```
Tweet: "I love this!"
Predicted: positive

Accuracy: 0.78
```

---

## ğŸ“Š Output

You will see:

* cleaned tweets printed during feature build
* progress steps logged
* sample predictions printed
* overall accuracy

---

## â— Notes

* This project uses the **training dataset for testing** (training accuracy).
* For real evaluation, add a train/test split later.
* Sparse matrices prevent memory freezes when creating TF-IDF features.

---

## ğŸš€ Possible Extensions

* Split data into train + test
* Add a real test dataset
* Support live user input
* Deploy using Flask or FastAPI
* Add additional ML models (SVM, Naive Bayes, Random Forest)

---

## ğŸ‰ Conclusion

This project demonstrates a **complete ML workflow**:
âœ” data loading
âœ” preprocessing
âœ” feature engineering
âœ” machine learning model
âœ” prediction
âœ” evaluation

All steps align with the textbook sentiment analysis pipeline and meet assignment requirements.

Enjoy experimenting! ğŸ˜

---

